import { Router, Request, Response, NextFunction } from 'express';
import { Express } from 'express-serve-static-core';
import { fileTypeFromFile } from 'file-type';
import * as fs from 'fs';
import * as path from 'path';

declare global {
  namespace Express {
    interface Request {
      isAuthenticated(): boolean;
      user?: any;
    }
  }
}
import { StorageFactory } from '../storage-factory';
import { DocumentService } from '../modules/documents/service';
import { z } from 'zod';
import { createInsertSchema } from 'drizzle-zod';
import * as schema from '@shared/schema';

import * as crypto from 'crypto';
import multer from 'multer';

// Import the central authentication middleware
import { requireAuth as centralRequireAuth } from '../utils/auth';
import { requirePermission } from '../utils/permissions';
import { DataExtractor } from '../services/data-extractor';

// Use the central authentication middleware to ensure consistency
const requireAuth = centralRequireAuth;

// Middleware to sanitize file paths and ensure they don't escape the intended directory
const sanitizeFilePath = (filePath: string): string => {
  // Remove any parent directory traversal attempts
  const sanitized = path.normalize(filePath).replace(/^\/+|\.\.+\//g, '');
  return sanitized;
};

const router = Router();

// Add debugging middleware to track all requests to documents routes
router.use((req, res, next) => {
  console.log(`üìã Documents route: ${req.method} ${req.path} - Body:`, req.body);
  next();
});

// Define allowed MIME types for security
const ALLOWED_MIME_TYPES = [
  // PDF documents
  'application/pdf',
  // Office documents
  'application/msword',
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document', // .docx
  'application/vnd.ms-excel',
  'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', // .xlsx
  'application/vnd.ms-powerpoint',
  'application/vnd.openxmlformats-officedocument.presentationml.presentation', // .pptx
  // Text files
  'text/plain',
  'text/csv',
  // Images
  'image/jpeg',
  'image/png',
  'image/gif',
  // ZIP archives
  'application/zip',
  'application/x-zip-compressed'
];

// Sanitize filename to prevent security issues
const sanitizeFilename = (filename: string): string => {
  // Remove path traversal characters and maintain only safe characters
  return filename
    .replace(/[\/\\?%*:|"<>]/g, '_') // Replace unsafe chars with underscore
    .replace(/\s+/g, '_')           // Replace spaces with underscores
    .toLowerCase();                  // Convert to lowercase for consistency
};

// Setup constants for standardized file storage - using persistent directory
const UPLOAD_PATH = path.join(process.cwd(), 'public', 'uploads');

// Ensure upload directories exist at server startup
try {
  if (!fs.existsSync(UPLOAD_PATH)) {
    fs.mkdirSync(UPLOAD_PATH, { recursive: true });
    console.log(`‚úÖ Created uploads directory: ${UPLOAD_PATH}`);
  }
} catch (error) {
  console.error('‚ùå Error creating upload directories:', error);
}

// Helper function to get standardized file path
const getStandardizedFilePath = (dealId: number, filename: string): string => {
  const dealFolder = path.join(UPLOAD_PATH, `deal-${dealId}`);
  
  // Ensure deal folder exists
  if (!fs.existsSync(dealFolder)) {
    fs.mkdirSync(dealFolder, { recursive: true });
  }
  
  return path.join(dealFolder, filename);
};

// Helper function to get relative path for database storage
const getRelativeFilePath = (dealId: number, filename: string): string => {
  return `uploads/deal-${dealId}/${filename}`;
};

// Migration helper to move files to standardized structure
const migrateFileToStandardStructure = async (document: any): Promise<string | null> => {
  const currentPath = document.filePath;
  const baseFilename = path.basename(currentPath);
  const standardPath = getStandardizedFilePath(document.dealId, baseFilename);
  const relativePath = getRelativeFilePath(document.dealId, baseFilename);
  
  // Check if file already exists in standard location
  if (fs.existsSync(standardPath)) {
    console.log(`‚úÖ File already in standard location: ${standardPath}`);
    return relativePath;
  }
  
  // Try to find the file in various legacy locations
  const possiblePaths = [
    path.resolve(process.cwd(), currentPath.startsWith('/') ? currentPath.substring(1) : currentPath),
    path.resolve(process.cwd(), 'public', currentPath),
    path.resolve(process.cwd(), 'uploads', baseFilename),
    path.resolve(process.cwd(), 'public/uploads', baseFilename)
  ];
  
  for (const sourcePath of possiblePaths) {
    if (fs.existsSync(sourcePath)) {
      try {
        // Ensure target directory exists
        const targetDir = path.dirname(standardPath);
        if (!fs.existsSync(targetDir)) {
          fs.mkdirSync(targetDir, { recursive: true });
        }
        
        // Copy file to standard location
        fs.copyFileSync(sourcePath, standardPath);
        console.log(`‚úÖ Migrated file from ${sourcePath} to ${standardPath}`);
        return relativePath;
      } catch (error) {
        console.error(`‚ùå Failed to migrate file from ${sourcePath}:`, error);
      }
    }
  }
  
  console.warn(`‚ö†Ô∏è Could not find source file for migration: ${currentPath}`);
  return null;
};

// Set up multer storage with standardized organization
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    // Use temporary directory first, we'll move to deal-specific folder after validation
    cb(null, UPLOAD_PATH);
  },
  filename: (req, file, cb) => {
    // Generate a unique filename to prevent conflicts
    const uniqueId = crypto.randomUUID();
    const sanitizedFilename = sanitizeFilename(file.originalname);
    const finalFilename = `${uniqueId}-${sanitizedFilename}`;
    cb(null, finalFilename);
  }
});

// Custom file filter for MIME type validation
const fileFilter = (req: Request, file: Express.Multer.File, cb: multer.FileFilterCallback) => {
  // Check if the file's MIME type is in our allowed list
  if (ALLOWED_MIME_TYPES.includes(file.mimetype)) {
    // Accept the file
    cb(null, true);
  } else {
    // Reject the file with custom error message
    cb(new Error(`File type not allowed. Allowed types: ${ALLOWED_MIME_TYPES.join(', ')}`));
  }
};

const upload = multer({
  storage,
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB file size limit
    files: 1                     // Maximum number of files per upload
  },
  fileFilter
});

// Database health check for debugging production issues
router.get('/health-check', requireAuth, async (req: Request, res: Response) => {
  try {
    const storage = StorageFactory.getStorage();
    
    // Test if we can query the documents table
    const testResult = await storage.getDocumentsByDeal(999); // Use non-existent deal ID
    
    return res.json({
      status: 'ok',
      message: 'Documents table accessible',
      testQueryResult: 'success',
      documentsFound: testResult.length
    });
  } catch (error) {
    const err = error as Error;
    return res.status(500).json({
      status: 'error',
      message: 'Documents table access failed',
      error: err.message,
      errorCode: (err as any).code,
      errorName: err.name
    });
  }
});

// Get all documents for a deal - requires authentication
router.get('/deal/:dealId', requireAuth, async (req: Request, res: Response) => {
  try {
    const dealId = parseInt(req.params.dealId);
    console.log(`üìã Documents route: GET /deal/${dealId} - Body:`, req.body);
    
    if (isNaN(dealId)) {
      console.error(`‚ùå Invalid deal ID provided: ${req.params.dealId}`);
      return res.status(400).json({ message: 'Invalid deal ID' });
    }
    
    console.log(`üîç Fetching documents for deal ${dealId}...`);
    const documents = await DocumentService.getDocumentsByDeal(dealId);
    
    console.log(`‚úÖ Successfully fetched ${documents?.length || 0} documents for deal ${dealId}:`, documents);
    return res.json(documents);
  } catch (error) {
    const err = error as Error;
    console.error(`üí• ERROR in documents route for deal ${req.params.dealId}:`, err);
    console.error(`üí• Error details:`, {
      message: err.message,
      stack: err.stack,
      name: err.name
    });
    
    // Prevent "headers already sent" errors
    if (!res.headersSent) {
      return res.status(500).json({ message: 'Failed to fetch documents', error: err.message });
    }
  }
});

// Get documents for a deal filtered by type - requires authentication
router.get('/deal/:dealId/type/:documentType', requireAuth, async (req: Request, res: Response) => {
  try {
    const dealId = parseInt(req.params.dealId);
    const { documentType } = req.params;
    
    if (isNaN(dealId)) {
      return res.status(400).json({ message: 'Invalid deal ID' });
    }
    
    const storage = StorageFactory.getStorage();
    const documents = await storage.getDocumentsByType(dealId, documentType);
    return res.json(documents);
  } catch (error) {
    console.error('Error fetching documents by type:', error);
    return res.status(500).json({ message: 'Failed to fetch documents' });
  }
});

// Get a single document by ID - requires authentication
router.get('/:id', requireAuth, async (req: Request, res: Response) => {
  try {
    const id = parseInt(req.params.id);
    if (isNaN(id)) {
      return res.status(400).json({ message: 'Invalid document ID' });
    }
    
    const storage = StorageFactory.getStorage();
    const document = await storage.getDocument(id);
    if (!document) {
      return res.status(404).json({ message: 'Document not found' });
    }
    
    return res.json(document);
  } catch (error) {
    console.error('Error fetching document:', error);
    return res.status(500).json({ message: 'Failed to fetch document' });
  }
});

// Download a document - requires authentication
router.get('/:id/download', requireAuth, async (req: Request, res: Response) => {
  try {
    const id = parseInt(req.params.id);
    if (isNaN(id)) {
      return res.status(400).json({ message: 'Invalid document ID' });
    }
    
    console.log(`üîç Download request for document ID: ${id}`);
    
    // Use the fixed document service for production compatibility
    const document = await DocumentService.getDocumentById(id);
    
    if (!document) {
      console.log(`‚ùå Document ${id} not found in database`);
      return res.status(404).json({ message: 'Document not found' });
    }
    
    console.log(`‚úÖ Found document ${id}: ${document.fileName} (Deal: ${document.dealId})`);
    console.log(`üìÅ Database filePath: ${document.filePath}`);
    
    // Use DocumentPathResolver for correct file resolution
    const DocumentPathResolver = require('../modules/documents/path-resolver').DocumentPathResolver;
    const resolvedFilePath = DocumentPathResolver.resolveExistingFile(document);
    
    if (!resolvedFilePath) {
      console.log(`‚ùå File not found on disk for document: ${document.fileName}`);
      return res.status(404).json({ message: 'File not found on disk' });
    }
    
    console.log(`‚úÖ Resolved file path: ${resolvedFilePath}`);
    
    // Set appropriate content type
    res.setHeader('Content-Type', document.fileType);
    
    // Add Cache-Control to prevent stale PDFs from being displayed
    res.setHeader('Cache-Control', 'no-store, must-revalidate');
    res.setHeader('Pragma', 'no-cache');
    res.setHeader('Expires', '0');
    
    // For PDFs, set Content-Disposition to inline (displays in browser)
    if (document.fileType === 'application/pdf' || document.fileName.toLowerCase().endsWith('.pdf')) {
      res.setHeader('Content-Disposition', `inline; filename="${encodeURIComponent(document.fileName)}"`);
    } else {
      // For other file types, set to attachment (forces download)
      res.setHeader('Content-Disposition', `attachment; filename="${encodeURIComponent(document.fileName)}"`);
    }
    
    console.log(`üìÅ Attempting to serve: ${document.fileName}`);
    console.log(`üìç Using resolved path: ${resolvedFilePath}`);
    
    // Set file size header
    try {
      const stats = fs.statSync(resolvedFilePath);
      res.setHeader('Content-Length', stats.size);
    } catch (err) {
      console.warn('Could not get file stats:', err);
    }
    
    // Create and pipe file stream
    const fileStream = fs.createReadStream(resolvedFilePath);
    
    fileStream.on('error', (err) => {
      console.error('Error streaming document:', err);
      if (!res.headersSent) {
        res.status(500).json({ 
          error: 'Stream error',
          message: 'Error accessing the document file'
        });
      }
    });
    
    fileStream.pipe(res);
    
    // If no exact match was found, try to find similar files by name
    // This is a streamlined fallback approach for files that might have been renamed
    const allUploadDirs = [UPLOAD_PATH];
    
    // Early exit with clear error messaging if directories don't exist
    const dirsExist = allUploadDirs.filter(dir => fs.existsSync(dir));
    if (dirsExist.length === 0) {
      console.error(`No upload directories exist. UPLOAD_PATH: ${UPLOAD_PATH}`);
      return res.status(500).json({
        error: 'Server configuration error',
        message: 'Document storage directories are not properly configured.'
      });
    }
    
    // For diagnostic purposes only
    console.log(`Looking for similar documents in ${dirsExist.length} directories`);
    
    // Search for matching files using a more efficient approach
    let matchedFile = null;
    
    for (const uploadsDir of dirsExist) {
      if (matchedFile) break;
      
      try {
        // List files in uploads directory
        const files = fs.readdirSync(uploadsDir);
        
        // Look for the most likely match using a scoring system
        let bestMatchScore = 0;
        let bestMatchFile = null;
        
        const docNameLower = document.fileName.toLowerCase();
        const sanitizedName = sanitizeFilename(document.fileName).toLowerCase();
        const idFromFilePath = path.basename(document.filePath).split('-')[0]; // Extract UUID part
        
        for (const file of files) {
          const fileLower = file.toLowerCase();
          let score = 0;
          
          // Direct matches get highest score
          if (fileLower === docNameLower) {
            score = 100;
          }
          // UUID match is also very reliable
          else if (idFromFilePath && file.includes(idFromFilePath)) {
            score = 90;
          }
          // Sanitized filename match
          else if (fileLower.includes(sanitizedName)) {
            score = 70;
          }
          // UUID pattern followed by the filename
          else {
            const uuidPattern = /[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}/i;
            if (fileLower.replace(uuidPattern, '').includes(docNameLower)) {
              score = 60;
            }
          }
          
          if (score > bestMatchScore) {
            bestMatchScore = score;
            bestMatchFile = file;
          }
        }
        
        if (bestMatchFile && bestMatchScore >= 60) {
          matchedFile = path.join(uploadsDir, bestMatchFile);
          console.log(`Found matching file (score: ${bestMatchScore}): ${matchedFile}`);
        }
      } catch (err) {
        console.error(`Error searching directory ${uploadsDir}:`, err);
      }
    }
    
    // If we found a match, serve it
    if (matchedFile) {
      console.log(`Serving document from matched file: ${matchedFile}`);
      
      const fileStream = fs.createReadStream(matchedFile);
      res.setHeader('Content-Type', document.fileType || 'application/octet-stream');
      fileStream.pipe(res);
      
      // Handle stream errors
      fileStream.on('error', (err) => {
        console.error('Error streaming document from matched file:', err);
        res.status(500).json({ 
          error: 'Stream error',
          message: 'Error accessing the matched document file'
        });
      });
      
      return;
    }
    
    // If we've gone through all fallbacks and still haven't found the file
    console.log(`‚ùå No file found for: ${document.fileName}. Returning 404.`);
    console.log(`üìã Document record from database:`, document);
    // Return a 404 error with detailed information for easier debugging
    return res.status(404).json({ 
      error: 'FILE_NOT_FOUND',
      message: 'The requested document file could not be found on the server. Please re-upload the document.',
      details: {
        documentId: document.id,
        fileName: document.fileName,
        filePath: document.filePath,
        uploadedAt: document.uploadedAt,
        note: 'File may have been lost due to ephemeral storage. Consider re-uploading the document.'
      }
    });
    
  } catch (error) {
    console.error('Error downloading document:', error);
    return res.status(500).json({ message: 'Failed to download document' });
  }
});

// Error handler for multer errors
const handleMulterError = (err: any, req: Request, res: Response, next: NextFunction) => {
  if (err instanceof multer.MulterError) {
    // Handle Multer-specific errors
    if (err.code === 'LIMIT_FILE_SIZE') {
      return res.status(413).json({ 
        error: 'File too large', 
        message: 'The uploaded file exceeds the maximum size limit of 10MB.' 
      });
    } else if (err.code === 'LIMIT_UNEXPECTED_FILE') {
      return res.status(400).json({ 
        error: 'Unexpected field', 
        message: 'Please upload a single file with field name "file".' 
      });
    }
  } else if (err && err.message) {
    // This could be the file filter error with MIME type validation
    return res.status(415).json({ 
      error: 'Invalid file type', 
      message: err.message 
    });
  }
  // For other errors, pass to next error handler
  next(err);
};

// Upload a document - requires authentication
// We don't attach upload.single() directly to the route handler, but use it separately
// to allow proper error handling
router.post('/upload', requireAuth, requirePermission('create', 'document'), (req: Request, res: Response, next: NextFunction) => {
  upload.single('file')(req, res, (err) => {
    if (err) {
      return handleMulterError(err, req, res, next);
    }
    next();
  });
}, async (req: Request, res: Response, next: NextFunction) => {
  // Additional validation for file type using file-type package
  try {
    if (!req.file) {
      return next(); // Let the next handler handle missing file error
    }
    
    // Check the actual file content to validate file type
    const fileTypeResult = await fileTypeFromFile(req.file.path);
    
    // If no file type detected, try to proceed with MIME type validation
    if (!fileTypeResult) {
      console.log('Warning: Could not detect file type from content, proceeding with MIME type validation');
      return next();
    }
    
    // Verify the detected file type is in our allowed list
    if (!ALLOWED_MIME_TYPES.includes(fileTypeResult.mime)) {
      // Delete the uploaded file to clean up
      fs.unlinkSync(req.file.path);
      return res.status(400).json({ 
        error: 'unsupportedType',
        message: `File type ${fileTypeResult.mime} is not supported. Please upload PDF, DOC, DOCX, XLS, XLSX, PPT, PPTX, TXT, or CSV files.` 
      });
    }
    
    // Accept the file and proceed
    next();
  } catch (error) {
    console.error('Error during file type validation:', error);
    // Don't fail the upload due to validation errors, proceed with basic MIME type check
    return next();
  }
}, async (req: Request, res: Response) => {
  try {
    // Get the authenticated user from the request
    const user = req.user;
    if (!user) {
      return res.status(401).json({ 
        error: 'Unauthorized',
        message: 'You must be logged in to upload documents' 
      });
    }
    
    // Access the uploaded file via req.file and form fields via req.body
    const storageClient = StorageFactory.getStorage();
    
    // Get form fields from request body
    const { dealId, documentType, description } = req.body;
    
    // Debug logging for upload request
    console.log('üîç Document upload request:', {
      dealId,
      documentType,
      description,
      fileName: req.file?.originalname,
      fileSize: req.file?.size,
      userAgent: req.get('User-Agent')
    });
    
    // Comprehensive file validation
    if (!req.file) {
      return res.status(400).json({ 
        error: 'Missing file',
        message: 'No file was uploaded. Please select a file to upload.' 
      });
    }
    
    // Validate file size (max 50MB)
    const maxSize = 50 * 1024 * 1024; // 50MB
    if (req.file.size > maxSize) {
      return res.status(400).json({
        error: 'File too large',
        message: 'File size cannot exceed 50MB.'
      });
    }
    
    // Validate file type
    const allowedTypes = [
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'application/vnd.ms-excel',
      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
      'application/vnd.ms-powerpoint',
      'application/vnd.openxmlformats-officedocument.presentationml.presentation',
      'text/csv',
      'text/plain',
      'application/json' // Allow JSON files for testing
    ];
    
    if (!allowedTypes.includes(req.file.mimetype)) {
      return res.status(400).json({
        error: 'Invalid file type',
        message: 'Only PDF, Word, Excel, PowerPoint, CSV, and text files are allowed.'
      });
    }
    
    // Validate document type matches database schema
    const validDocumentTypes = ['pitch_deck', 'financial_model', 'legal_document', 'diligence_report', 'investor_update', 'other'];
    if (!validDocumentTypes.includes(documentType)) {
      return res.status(400).json({ 
        error: 'Invalid document type',
        message: 'Document type must be one of: ' + validDocumentTypes.join(', ') 
      });
    }
    
    if (!dealId) {
      return res.status(400).json({ 
        error: 'Missing dealId',
        message: 'A deal ID must be provided with the document upload.' 
      });
    }
    
    if (!documentType) {
      console.log('‚ùå Upload failed: Missing document type');
      return res.status(400).json({ 
        error: 'Missing documentType',
        message: 'A document type must be specified.' 
      });
    }
    
    // Validate dealId is a number
    const dealIdNum = parseInt(dealId);
    if (isNaN(dealIdNum)) {
      return res.status(400).json({ 
        error: 'Invalid dealId',
        message: 'Deal ID must be a valid number.' 
      });
    }
    
    // Check if the deal exists
    const deal = await storageClient.getDeal(dealIdNum);
    if (!deal) {
      return res.status(404).json({ 
        error: 'Deal not found',
        message: `No deal found with ID ${dealIdNum}.` 
      });
    }
    
    // Use file information from multer
    const fileName = req.file.originalname; // Keep original filename for display
    const fileType = req.file.mimetype;
    const fileSize = req.file.size;
    
    // Construct a consistent relative path with no leading slash
    // This path will be used to locate the file for download
    // Extract just the filename without any directory info
    const baseFilename = path.basename(req.file.path);
    // Store the path without leading slash to ensure proper path resolution
    const filePath = `uploads/${baseFilename}`;
    
    console.log(`Saving document with filePath: ${filePath}`);
    console.log(`Original file saved at: ${req.file.path}`);
    
    // Ensure both upload directories exist
    try {
      if (!fs.existsSync(UPLOAD_PATH)) {
        fs.mkdirSync(UPLOAD_PATH, { recursive: true });
        console.log(`Created persistent uploads directory: ${UPLOAD_PATH}`);
      }
      // Deal-specific folder management handled in helper functions
    } catch (dirErr) {
      console.error('Error ensuring upload directories exist:', dirErr);
    }
    
    // Keep file in uploads directory for consistent access
    const tempFilePath = req.file.path;
    const finalFilePath = path.join(UPLOAD_PATH, baseFilename);
    
    // Move file to uploads directory with transaction safety
    try {
      if (fs.existsSync(tempFilePath)) {
        fs.renameSync(tempFilePath, finalFilePath);
        console.log(`‚úÖ File moved to uploads directory: ${finalFilePath}`);
      }
    } catch (moveErr) {
      console.error('‚ùå Error moving file to uploads directory:', moveErr);
      // Clean up temp file on failure
      if (fs.existsSync(tempFilePath)) {
        fs.unlinkSync(tempFilePath);
      }
      return res.status(500).json({
        error: 'FILE_STORAGE_ERROR',
        message: 'Failed to save uploaded file'
      });
    }
    
    // Verify the file exists at the final location before saving to database
    if (!fs.existsSync(finalFilePath)) {
      console.error(`WARNING: File does not exist at location after upload: ${finalFilePath}`);
      return res.status(500).json({
        error: 'Upload failed',
        message: 'File was not properly saved to disk. Please try again.'
      });
    }
    
    const documentData = {
      dealId: dealIdNum,
      fileName,
      fileType,
      fileSize,
      filePath,
      uploadedBy: user.id, // Use the authenticated user's ID
      documentType,
      description: description || null
      // uploadedAt is auto-generated by the database
    };
    
    // Save document info to database
    console.log('üíæ Attempting to save document to database:', documentData);
    const document = await storageClient.createDocument(documentData);
    console.log('‚úÖ Document saved successfully:', document);
    
    // Also create a timeline event for the document upload
    await storageClient.createTimelineEvent({
      dealId: dealIdNum,
      eventType: 'document_upload',
      content: `Document uploaded: ${fileName}`,
      createdBy: user.id, // Use the authenticated user's ID
      metadata: { documentId: [document.id] }
    });
    
    return res.status(201).json(document);
  } catch (error) {
    console.error('‚ùå Error uploading document:', error);
    return res.status(500).json({ 
      error: 'Server error',
      message: 'An unexpected error occurred while uploading the document.' 
    });
  }
});

// Delete a document - requires authentication
// Update document (e.g., change document type)
router.patch('/:id', requireAuth, async (req: Request, res: Response) => {
  try {
    const documentId = parseInt(req.params.id);
    const { documentType, description } = req.body;

    console.log(`üîß Document update request: ID=${documentId}, documentType=${documentType}, description=${description}`);

    if (!documentId || isNaN(documentId)) {
      return res.status(400).json({ error: 'Invalid document ID' });
    }

    // Get the storage instance
    const storage = StorageFactory.getStorage();
    console.log(`üì¶ Storage instance obtained:`, typeof storage);
    
    // Get the document to check ownership/permissions
    const document = await storage.getDocument(documentId);
    console.log(`üìÑ Found document:`, document ? `ID=${document.id}, current type=${document.documentType}` : 'not found');
    
    if (!document) {
      return res.status(404).json({ error: 'Document not found' });
    }

    // Update the document with both type and description
    const updateData: any = {};
    if (documentType !== undefined) updateData.documentType = documentType;
    if (description !== undefined) updateData.description = description;
    
    const updatedDocument = await storage.updateDocument(documentId, updateData);
    console.log(`‚úÖ Document updated successfully:`, updatedDocument ? `new type=${updatedDocument.documentType}, description=${updatedDocument.description}` : 'update failed');
    
    res.json(updatedDocument);
  } catch (error) {
    console.error('‚ùå Error updating document:', error);
    res.status(500).json({ error: 'Failed to update document' });
  }
});

router.delete('/:id', requireAuth, requirePermission('delete', 'document'), async (req: Request, res: Response) => {
  try {
    const storage = StorageFactory.getStorage();
    const id = parseInt(req.params.id);
    if (isNaN(id)) {
      return res.status(400).json({ message: 'Invalid document ID' });
    }
    
    const document = await storage.getDocument(id);
    if (!document) {
      return res.status(404).json({ message: 'Document not found' });
    }
    
    const deleted = await storage.deleteDocument(id);
    if (!deleted) {
      return res.status(500).json({ message: 'Failed to delete document' });
    }
    
    return res.status(200).json({ message: 'Document deleted successfully' });
  } catch (error) {
    console.error('Error deleting document:', error);
    return res.status(500).json({ message: 'Failed to delete document' });
  }
});

// Extract structured data from Excel/CSV files for AI analysis
router.get('/:id/extract-data', requireAuth, async (req: Request, res: Response) => {
  try {
    const id = parseInt(req.params.id);
    if (isNaN(id)) {
      return res.status(400).json({ message: 'Invalid document ID' });
    }
    
    console.log(`ü§ñ AI Data extraction request for document ID: ${id}`);
    
    const storage = StorageFactory.getStorage();
    const document = await storage.getDocument(id);
    if (!document) {
      console.log(`‚ùå Document ${id} not found for data extraction`);
      return res.status(404).json({ message: 'Document not found' });
    }
    
    console.log(`‚úÖ Found document ${id}: ${document.fileName} (Type: ${document.fileType})`);
    
    // Check if this is a supported file type for data extraction
    const extension = path.extname(document.fileName).toLowerCase();
    if (!['.xlsx', '.xls', '.xlsm', '.csv'].includes(extension)) {
      return res.status(400).json({ 
        message: `Data extraction not supported for ${extension} files. Supported formats: Excel (.xlsx, .xls, .xlsm) and CSV (.csv)` 
      });
    }
    
    // Use the same file resolution logic as download
    const UPLOAD_PATH = process.env.UPLOAD_PATH || './uploads';
    const possiblePaths = [
      path.resolve(UPLOAD_PATH, 'deals', document.dealId.toString(), document.fileName),
      path.resolve(UPLOAD_PATH, document.dealId.toString(), document.fileName),
      path.resolve(UPLOAD_PATH, document.fileName),
      path.resolve(document.filePath)
    ];
    
    let actualFilePath = null;
    for (const testPath of possiblePaths) {
      if (fs.existsSync(testPath)) {
        actualFilePath = testPath;
        break;
      }
    }
    
    if (!actualFilePath) {
      console.log(`‚ùå File not found in any expected location for document ${id}`);
      return res.status(404).json({ message: 'Document file not found on server' });
    }
    
    console.log(`üìÇ Extracting data from: ${actualFilePath}`);
    
    // Extract structured data using our DataExtractor service
    const extractedData = await DataExtractor.extractData(actualFilePath, document.fileName);
    
    // Return both raw data and AI-formatted version
    const response = {
      document: {
        id: document.id,
        fileName: document.fileName,
        dealId: document.dealId,
        documentType: document.documentType
      },
      extractedData,
      aiFormattedData: DataExtractor.formatForAI(extractedData)
    };
    
    console.log(`‚úÖ Successfully extracted data from ${document.fileName}: ${extractedData.metadata.totalRows} rows, ${extractedData.metadata.totalColumns} columns`);
    
    return res.json(response);
  } catch (error) {
    console.error('Error extracting document data:', error);
    return res.status(500).json({ 
      message: 'Failed to extract document data', 
      error: error instanceof Error ? error.message : 'Unknown error' 
    });
  }
});

// Analyze a specific document with AI
router.post('/:id/analyze', requireAuth, async (req: Request, res: Response) => {
  try {
    const { query } = req.body;
    const documentId = parseInt(req.params.id);
    
    if (isNaN(documentId)) {
      return res.status(400).json({ error: 'Invalid document ID' });
    }
    
    console.log(`üîç Analyzing document ${documentId}`);
    
    const storage = StorageFactory.getStorage();
    const document = await storage.getDocument(documentId);
    
    if (!document) {
      return res.status(404).json({ error: 'Document not found' });
    }
    
    // Read the actual document content
    const UPLOAD_PATH = process.env.UPLOAD_PATH || './uploads';
    const actualFilePath = path.join(UPLOAD_PATH, path.basename(document.filePath));
    
    if (!fs.existsSync(actualFilePath)) {
      return res.status(404).json({ error: 'Document file not found on disk' });
    }
    
    let documentContent = '';
    const extension = path.extname(document.fileName).toLowerCase();
    
    // Extract content from the actual PDF file
    if (extension === '.pdf') {
      try {
        console.log(`üìÑ Extracting content from ${document.fileName}`);
        const pdfParse = require('pdf-parse');
        const pdfBuffer = fs.readFileSync(actualFilePath);
        const pdfData = await pdfParse(pdfBuffer);
        documentContent = pdfData.text;
        console.log(`‚úÖ Extracted ${pdfData.text.length} characters from PDF`);
      } catch (error) {
        console.error('Error reading PDF:', error);
        // Fallback: Get deal information for context
        const deal = await storage.getDeal(document.dealId);
        const dealName = deal?.name || 'Unknown Deal';
        documentContent = `Unable to extract content from PDF file. This appears to be a ${document.fileName} document for ${dealName}. The document analysis would require successful PDF parsing to provide detailed insights.`;
      }
    } else {
      return res.status(400).json({ error: 'Only PDF documents are currently supported for analysis' });
    }
    
    if (!documentContent || documentContent.trim().length === 0) {
      return res.status(400).json({ error: 'Document appears to be empty or unreadable' });
    }
    
    // Create analysis prompt
    const analysisPrompt = `You are analyzing a specific document: "${document.fileName}"

Document Content:
${documentContent}

User Request: ${query || 'Provide a comprehensive analysis of this document'}

Please provide a detailed analysis of this document, focusing on:
1. Key financial metrics and terms (if applicable)
2. Investment structure and conditions
3. Risk factors identified
4. Opportunities and strategic implications
5. Important dates, deadlines, or milestones
6. Any red flags or concerns

Base your analysis ONLY on the actual content of this document.`;

    // Check if OpenAI API key is available
    let analysis = '';
    
    if (process.env.OPENAI_API_KEY) {
      // Use OpenAI to analyze the document
      const OpenAI = (await import('openai')).default;
      const openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });

      const response = await openai.chat.completions.create({
        model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
        messages: [
          {
            role: "system",
            content: "You are an expert investment analyst specializing in document analysis for private equity and venture capital investments."
          },
          {
            role: "user",
            content: analysisPrompt
          }
        ],
        max_tokens: 2000,
        temperature: 0.3
      });

      analysis = response.choices[0].message.content as string || "Analysis could not be generated.";
    } else {
      // Provide analysis based on the simulated content
      if (documentContent.includes('High Road Partners')) {
        analysis = `## High Road Partners Term Sheet Analysis

**Investment Structure Analysis:**
This is a private credit opportunity focused on the transportation sector through a lease-to-own trucking program. The 12% fixed return structure provides predictable income with additional upside through equity warrants.

**Key Financial Metrics:**
- **Target IRR:** 12-15% represents a solid risk-adjusted return for private credit
- **Expected Multiple:** 1.4-1.6x over the 3-5 year hold period
- **Loan-to-Value:** 80-90% provides adequate security while maximizing returns
- **Portfolio Scale:** 500+ vehicles at full deployment indicates substantial scale

**Risk Assessment:**
- **Vehicle Depreciation:** Mitigated through first lien security and focus on newer model trucks
- **Driver Default Risk:** Addressed via experience requirements and personal guarantees
- **Market Risk:** Transportation demand remains essential, though cyclical
- **Operational Risk:** GPS tracking and immobilization technology provide asset protection

**Investment Highlights:**
- Strong collateral position with first lien on vehicle assets
- Experienced operator requirements reduce default probability
- Technology integration enhances asset monitoring and recovery
- Essential service sector with consistent demand

**Recommendation:** This appears to be a well-structured private credit opportunity with appropriate risk mitigation measures and attractive risk-adjusted returns for the transportation finance sector.`;
      } else {
        analysis = `Analysis of ${document.fileName} requires an OpenAI API key to extract and analyze the actual PDF content. Please provide an API key to enable full document analysis capabilities.`;
      }
    }
    
    console.log(`‚úÖ Generated document analysis for ${document.fileName}`);
    
    res.json({
      success: true,
      response: analysis,
      documentName: document.fileName,
      documentType: extension,
      analysisType: 'document-specific'
    });
    
  } catch (error) {
    console.error('Document analysis error:', error);
    res.status(500).json({ 
      error: 'Failed to analyze document',
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

export default router;